{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "24ebb5b9",
      "metadata": {
        "id": "24ebb5b9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df= pd.read_table('movies.csv', sep=',')\n",
        "movies_df['movieId'] = movies_df['movieId'].astype('uint32')\n",
        "users_df=pd.read_csv('users_df.csv', index_col=0)\n",
        "user_movie_matrix = pd.read_csv('user_movie_matrix.csv', index_col='userId')\n",
        "correlation_df=pd.read_csv('correlation_matrix.csv', index_col='userId')\n",
        "correlation_df.columns = correlation_df.columns.astype(int)"
      ],
      "metadata": {
        "id": "DbOHS_-vLTr6"
      },
      "id": "DbOHS_-vLTr6",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kolaborativno filtriranje"
      ],
      "metadata": {
        "id": "CGQJbBgUJfp_"
      },
      "id": "CGQJbBgUJfp_"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "28c7c9e6",
      "metadata": {
        "id": "28c7c9e6"
      },
      "outputs": [],
      "source": [
        "def get_most_similar_users(user_id, n, correlation_df):\n",
        "    user_correlations = correlation_df[user_id].drop(user_id)\n",
        "    sorted_users = user_correlations.sort_values(ascending=False)\n",
        "    top_n_similar_users = sorted_users.head(n).index.tolist()\n",
        "    return top_n_similar_users\n",
        "\n",
        "def get_movie_recommendations(user_id, m, similar_users, user_movie_matrix, min_correlation=0.05):\n",
        "    user_index = user_movie_matrix.index.get_loc(user_id)\n",
        "\n",
        "    # Sum the correlations (weights) and weighted scores of similar users\n",
        "    weights_sum = 0\n",
        "    weighted_scores_sum = np.zeros_like(user_movie_matrix.loc[user_id])\n",
        "\n",
        "    for similar_user in similar_users:\n",
        "        similar_user_index = user_movie_matrix.index.get_loc(similar_user)\n",
        "        correlation = correlation_df.at[user_id, similar_user]\n",
        "\n",
        "        if np.isnan(correlation) or correlation < min_correlation:\n",
        "            continue\n",
        "            \n",
        "        weights_sum += correlation\n",
        "        weighted_scores_sum += user_movie_matrix.loc[similar_user] * correlation\n",
        "        \n",
        "    # Normalize the weighted scores by dividing by the sum of correlations\n",
        "    if weights_sum != 0:\n",
        "        normalized_scores = weighted_scores_sum / weights_sum\n",
        "    else:\n",
        "        normalized_scores = np.zeros_like(user_movie_matrix.loc[user_id])\n",
        "\n",
        "    # Remove the movies that the user has already rated\n",
        "    user_rated_movies = user_movie_matrix.loc[user_id]\n",
        "    normalized_scores[user_rated_movies != 0] = 0\n",
        "    \n",
        "    # Get the top m movie recommendations\n",
        "    # Get a pandas Series with the movie indices as the index\n",
        "    normalized_scores_series = pd.Series(normalized_scores, index=user_movie_matrix.columns)\n",
        "    # Select the top m movie recommendations by using the nlargest function on the pandas Series\n",
        "    recommended_movie_ids = normalized_scores_series.nlargest(m).index\n",
        "    return recommended_movie_ids.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cold start"
      ],
      "metadata": {
        "id": "lVoC97FiNDyA"
      },
      "id": "lVoC97FiNDyA"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "13fda2bf",
      "metadata": {
        "id": "13fda2bf"
      },
      "outputs": [],
      "source": [
        "country_to_region = {\n",
        "    'Belarus': 'Eastern Europe',\n",
        "    'Bulgaria': 'Eastern Europe',\n",
        "    'Czech Republic': 'Eastern Europe',\n",
        "    'Hungary': 'Eastern Europe',\n",
        "    'Poland': 'Eastern Europe',\n",
        "    'Moldova': 'Eastern Europe',\n",
        "    'Romania': 'Eastern Europe',\n",
        "    'Russia': 'Eastern Europe',\n",
        "    'Slovakia': 'Eastern Europe',\n",
        "    'Ukraine': 'Eastern Europe',\n",
        "    'Ã…land Islands': 'Northern Europe',\n",
        "    'Denmark': 'Northern Europe',\n",
        "    'Estonia': 'Northern Europe',\n",
        "    'Faroe Islands': 'Northern Europe',\n",
        "    'Finland': 'Northern Europe',\n",
        "    'Iceland': 'Northern Europe',\n",
        "    'Ireland': 'Northern Europe',\n",
        "    'Isle of Man': 'Northern Europe',\n",
        "    'Latvia': 'Northern Europe',\n",
        "    'Lithuania': 'Northern Europe',\n",
        "    'Norway': 'Northern Europe',\n",
        "    'Svalbard and Jan Mayen Islands': 'Northern Europe',\n",
        "    'Sweden': 'Northern Europe',\n",
        "    'United Kingdom': 'Northern Europe',\n",
        "    'Albania': 'Southern Europe',\n",
        "    'Andorra': 'Southern Europe',\n",
        "    'Bosnia and Herzegovina': 'Southern Europe',\n",
        "    'Croatia': 'Southern Europe',\n",
        "    'Gibraltar': 'Southern Europe',\n",
        "    'Greece': 'Southern Europe',\n",
        "    'Holy See': 'Southern Europe',\n",
        "    'Italy': 'Southern Europe',\n",
        "    'Malta': 'Southern Europe',\n",
        "    'Montenegro': 'Southern Europe',\n",
        "    'North Macedonia': 'Southern Europe',\n",
        "    'Portugal': 'Southern Europe',\n",
        "    'San Marino': 'Southern Europe',\n",
        "    'Serbia': 'Southern Europe',\n",
        "    'Slovenia': 'Southern Europe',\n",
        "    'Spain': 'Southern Europe',\n",
        "    'Austria': 'Western Europe',\n",
        "    'Belgium': 'Western Europe',\n",
        "    'France': 'Western Europe',\n",
        "    'Germany': 'Western Europe',\n",
        "    'Liechtenstein': 'Western Europe',\n",
        "    'Luxembourg': 'Western Europe',\n",
        "    'Monaco': 'Western Europe',\n",
        "    'Netherlands': 'Western Europe',\n",
        "    'Switzerland': 'Western Europe',\n",
        "    'Channel Islands': 'Northern Europe'\n",
        "}\n",
        "\n",
        "age_ranges = {\n",
        "    'Teenagers (13-19)': (13, 19),\n",
        "    'Young Adults (20-25)': (20, 25),\n",
        "    'Adults (26-35)': (26, 35),\n",
        "    'Middle-aged Adults (36-45)': (36, 45),\n",
        "    'Senior Adults (46-65)': (46, 65)\n",
        "}\n",
        "\n",
        "min_age = 13\n",
        "max_age = 65\n",
        "\n",
        "def normalized_difference(a, b, min_age, max_age):\n",
        "    return np.abs((a - min_age) - (b - min_age)) / (max_age - min_age)\n",
        "\n",
        "def find_similar_users(users_df, new_user, n):\n",
        "    # Get new user details\n",
        "    new_sex = new_user['sex'].item()\n",
        "    new_age_group = new_user['age_group'].item()\n",
        "    new_age = new_user['age'].item()\n",
        "    new_country = new_user['country'].item()\n",
        "    new_region = new_user['region'].item()\n",
        "\n",
        "    # Compute age distance range\n",
        "    min_age = users_df['age'].min()\n",
        "    max_age = users_df['age'].max()\n",
        "\n",
        "    # Calculate age group similarity\n",
        "    age_distance = normalized_difference(users_df['age'], new_age, min_age, max_age)\n",
        "    age_similarity = 0.45 * (1 - age_distance)\n",
        "\n",
        "    # Calculate overall similarity\n",
        "    similarity_scores = (\n",
        "        (users_df['sex'] == new_sex).astype(float) * 0.35 +\n",
        "        (users_df['age_group'] == new_age_group).astype(float) * age_similarity +\n",
        "        (users_df['country'] == new_country).astype(float) * 0.15 +\n",
        "        (users_df['region'] == new_region).astype(float) * 0.05\n",
        "    )\n",
        "\n",
        "    # Sort users by similarity scores and get top n\n",
        "    top_indices = np.argsort(similarity_scores)[::-1][:n]\n",
        "    top_similarities = similarity_scores[top_indices]\n",
        "\n",
        "    # Get top n similar users\n",
        "    similar_users = users_df.loc[top_indices]\n",
        "\n",
        "    return similar_users, top_similarities\n",
        "\n",
        "def get_new_user(new_index):\n",
        "    age_distribution = users_df['age'].value_counts(normalize=True)\n",
        "    sex_distribution = users_df['sex'].value_counts(normalize=True)\n",
        "    region_distribution = users_df['region'].value_counts(normalize=True)\n",
        "    country_distribution = users_df['country'].value_counts(normalize=True)\n",
        "    \n",
        "    new_age = np.random.choice(age_distribution.index, p=age_distribution.values) \n",
        "    new_sex = np.random.choice(sex_distribution.index, p=sex_distribution.values)\n",
        "    new_country = np.random.choice(country_distribution.index, p=country_distribution.values)\n",
        "\n",
        "    new_region = country_to_region[new_country]\n",
        "    new_age_group = pd.cut([new_age], bins=[12, 19, 25, 35, 45, 65], labels=list(age_ranges))\n",
        "\n",
        "    \n",
        "    new_user = pd.DataFrame({\n",
        "        'userId': [new_index],\n",
        "        'sex': [new_sex],\n",
        "        'age': [new_age],\n",
        "        'country': [new_country],\n",
        "        'region': [new_region]\n",
        "    })\n",
        "    \n",
        "    new_user['age_group_pom'] = pd.cut(new_user['age'], bins=[13, 19, 25, 35, 45, 65], labels=list(age_ranges))\n",
        "    new_user.insert(new_user.columns.get_loc('age') + 1, 'age_group', new_user['age_group_pom'])\n",
        "  \n",
        "    return new_user.drop('age_group_pom', axis=1)    \n",
        "\n",
        "def get_movie_recommendations_cold_start(m, similar_users, similarities, user_movie_matrix, min_correlation=0.35):\n",
        "\n",
        "    weights_sum = 0\n",
        "    weighted_scores_sum = np.zeros_like(user_movie_matrix.loc[similar_users[0]])\n",
        "\n",
        "    for similar_user, similarity in zip(similar_users, similarities):\n",
        "        similar_user_index = user_movie_matrix.index.get_loc(similar_user)\n",
        "\n",
        "        if np.isnan(similarity) or similarity < min_correlation:\n",
        "            continue\n",
        "            \n",
        "        weights_sum += similarity\n",
        "        weighted_scores_sum += user_movie_matrix.loc[similar_user] * similarity\n",
        "        \n",
        "    # Normalize the weighted scores by dividing by the sum of correlations\n",
        "    if weights_sum != 0:\n",
        "        normalized_scores = weighted_scores_sum / weights_sum\n",
        "    else:\n",
        "        normalized_scores = np.zeros_like(user_movie_matrix.loc[similar_user[0]])\n",
        "\n",
        "    \n",
        "    # Get the top m movie recommendations\n",
        "    # Get a pandas Series with the movie indices as the index\n",
        "    normalized_scores_series = pd.Series(normalized_scores, index=user_movie_matrix.columns)\n",
        "    # Select the top m movie recommendations by using the nlargest function on the pandas Series\n",
        "    recommended_movie_ids = normalized_scores_series.nlargest(m).index\n",
        "    return recommended_movie_ids.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recomendation model"
      ],
      "metadata": {
        "id": "It3Rcb4H1tka"
      },
      "id": "It3Rcb4H1tka"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_id, num_similar_users, num_recommednations):\n",
        "  if user_id in correlation_df.columns:\n",
        "      similar_users = get_most_similar_users(user_id, num_similar_users, correlation_df)\n",
        "      recommended_movie_ids = get_movie_recommendations(user_id, num_recommednations, similar_users, user_movie_matrix, min_correlation=0.05)\n",
        "      recommended_movie_titles = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]['title']\n",
        "\n",
        "      return similar_users, list(recommended_movie_ids), list(recommended_movie_titles)\t\n",
        "\n",
        "  new_user=get_new_user(user_id)\n",
        "  similar_users, top_similarities=find_similar_users(users_df, new_user, num_similar_users)\n",
        "  recommended_movie_ids = get_movie_recommendations_cold_start(num_recommednations, similar_users['userId'].tolist(), top_similarities, user_movie_matrix, min_correlation=0.5)\n",
        "  recommended_movie_titles = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]['title']\n",
        "\n",
        "  return list(similar_users['userId']), list(recommended_movie_ids), list(recommended_movie_titles)\t"
      ],
      "metadata": {
        "id": "VMbTErXc1wSh"
      },
      "id": "VMbTErXc1wSh",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id=700\n",
        "num_similar_users=5\n",
        "num_recommednations=10\n",
        "\n",
        "similar_users, recommended_movie_ids, recommended_movie_titles=get_recommendations(user_id, num_similar_users, num_recommednations)\n",
        "\n",
        "print(\"Similar users to user\", user_id, \"are:\", similar_users)\n",
        "print(\"Recommended movies are:\\n\", '\\n'.join(str(item) for item in recommended_movie_titles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3M9tw4s4StL",
        "outputId": "d46bbe31-818d-4034-8115-c7b19a6794e0"
      },
      "id": "x3M9tw4s4StL",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar users to user 700 are: [75, 335, 54, 342, 280]\n",
            "Recommended movies are:\n",
            " Clerks (1994)\n",
            "Star Wars: Episode IV - A New Hope (1977)\n",
            "Shawshank Redemption, The (1994)\n",
            "Terminator 2: Judgment Day (1991)\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980)\n",
            "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
            "Jungle Book, The (1967)\n",
            "For a Few Dollars More (Per qualche dollaro in piÃ¹) (1965)\n",
            "Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
            "I Am Sam (2001)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}